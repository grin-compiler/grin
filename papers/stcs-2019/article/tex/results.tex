\documentclass[main.tex]{subfiles}
\begin{document}
	
	In this section, we present the initial results of our implementation of the GRIN framework. The measurements presented here can only be considered preliminary, given the compiler needs further work to be comparable to systems like the Glasgow Haskell Compiler or the Idris compiler~\cite{idris}. Nevertheless, these statistics are still relevant, since they provide valuable information about the effectiveness of the optimizer.
	
	\subsection{Measured programs}
	
	%TODO: include code of Length
	The measurements were taken using the Idris front end and LLVM back end of the compiler. Each test program --- besides ``Length" --- was adopted from the book \textit{Type-driven development with Idris}~\cite{tdd-idris} by Edwin Brady. These are small Idris programs demonstrating a certain aspect of the language.
	
	``Length" is an Idris program, calculating the length of a list containing the natural numbers from 1 to 100. This example was mainly constructed to test how the dead data elimination pass can transform the inner structure of a list into a simple natural number (see Section~\ref{sec:dde}).
	
	\subsection{Measured metrics}
	
	Each test program went through the compilation pipeline described in Section~\ref{sec:idris-front-end}, and measurements were taken at certain points during the compilation. The programs were subject to three different types of measurements.
	
	\vspace{0.25cm}
	\begin{itemize}
		\item Static, compile time measurements of the GRIN code.
		\item Dynamic, runtime measurements of the interpreted GRIN code.
		\item Dynamic, runtime measurements of the executed binaries.
	\end{itemize}
	\vspace{0.25cm}

	The compile time measurements were taken during the GRIN optimization passes, after each transformation. The measured metrics were the number of \pilcode{store}s, \pilcode{fetch}es and function definitions. These measurements ought to illustrate how the GRIN code becomes more and more efficient during the optimization process. The corresponding diagrams for the static measurements are Diagrams~\ref{diagram:length-stats-ct}~to~\ref{diagram:reverse-stats-ct}. On the horizontal axis, we can see the indices of the transformations in the pipeline, and on the vertical axis, we can see the number of the corresponding syntax tree nodes. Reading these diagram from left to right, we can observe the continuous evolution of the GRIN program throughout the optimization process.
	
	The runtime measurements of the interpreted GRIN programs were taken at three points during the compilation process. First, right after the GRIN code is generated from the Idris byte code; second, after the regular optimization passes; and finally, at the end of the entire optimization pipeline. As can be seen on Figure~\ref{fig:idris-compilation-pipeline}, the regular optimizations are run a second time right after the dead data elimination pass. This is because the DDE pass can enable further optimizations. To clarify, the third runtime measurement of the interpreted GRIN program was taken after the second set of regular optimizations. The measured metrics were the number of executed function calls, case pattern matches, \pilcode{store}s and \pilcode{fetch}es. The goal of these measurements is to compare the GRIN programs at the beginning and at the end of the optimization pipeline, as well as to evaluate the efficiency of the dead data elimination pass. The corresponding diagrams for these measurement are Diagrams~\ref{diagram:length-stats-rt}~to~\ref{diagram:reverse-stats-rt}.

	%TODO: add comment about default idris program

	The runtime measurements of the binaries were taken at the exact same points as the runtime measurements of the interpreted GRIN code. Their goal is similar as well, however they ought to compare the generated binaries instead of the GRIN programs. The measured metrics were the size of the binary, the number of executed user-space instructions, stores, loads, total heap memory usage (in bytes) and execution speed (in milliseconds)\footnote{The execution speed was measured by averaging the result of 1000 measurements}. The binaries were generated by the LLVM back end described in Section~\ref{subsec:llvm-back-end} with varying optimization levels for the LLVM Optimizer. The optimization levels are indicated in the corresponding tables: Tables~\ref{table:length-binary-results}~to~\ref{table:reverse-binary-results}. Where the optimization level is not specified, the default, \pilcode{O0} level was used. As for the LLVM Static Compiler and Clang, the most aggressive, \pilcode{O3} level was set for all the measurements.
	
	There are also measurements for the binaries generated by the Idris compiler. These were compiled using the highest (\pilcode{O3}) optimization level and the C back end. For these executables, the size is not included, because Idris compiles a full-fledged runtime system into the binary. Since our Idris back end only has a mnimal runtime yet, the sizes of the binaries are not comparable. However, all other metrics are, because during these measurements, Idris' garbage collector was never triggered. This can be accomplished by configuring the initial size of the heap memory through the runtime system of Idris. This allows us to compare Idris and GRIN binaries despite the \emph{yet} non-implemented garbage collector for GRIN.
	
	\subsection{Measurement setup}
	
	All the measurements were performed on a machine with \pilcode{Intel(R) Core(TM) i7-4710HQ CPU @ 2.50GHz} processor and \pilcode{Ubuntu 18.04 bionic} operating system with \pilcode{4.15.0-46-generic} kernel. The Idris compiler used by the front-end is of version 1.3.1, and the LLVM used by the back end is of version 7.
	
	The actual commands for the binary generation are detailed in Program~code~\ref{code:binary-gen}. That script has two parameters: \pilcode{N} and \pilcode{llvm-in}. \pilcode{N} is the optimization level for the LLVM Optimizer, and \pilcode{llvm-in} is the LLVM program generated from the optimized GRIN code.
	
	\vspace{-0.5cm}
	\begin{codeFloat}[h]
		\begin{bash}
			opt-7 -ON <llvm-in> -o <llvm-out> 
			llc-7 -O3 -relocation-model=pic -filetype=obj -o <object-file>
			clang-7 -O3 prim_ops.c runtime.c <object-file> -s -o <executable>
		\end{bash}
		\caption{Commands for binary generation}
		\label{code:binary-gen}
	\end{codeFloat}
	\vspace{-0.5cm}
	
	As for the runtime measurements of the binary, we used the \pilcode{perf} tool, the runtime of Idris and the minimal runtime of GRIN. The \pilcode{perf} command can be seen in Program~code~\ref{code:binary-measurements} which was used to count the number of executed user space instructions, stores, loads and to measure the execution speeds. The runtimes were used to determine the memory usage, and to make sure that Idris' garbage collector is never triggered.

	\vspace{-0.5cm}
	\begin{codeFloat}[h]
		\begin{bash}
			perf stat -e cpu/mem-stores/u -e "r81d0:u" -e instructions:u <executable>
		\end{bash}
		\caption{Command for runtime measurements of the binary}
		\label{code:binary-measurements}
	\end{codeFloat}
	\vspace{-0.5cm}
	
	
	\subsection{Length}
	
	The first thing we can notice on the runtime statistics of the GRIN code, is that the GRIN optimizer significantly reduced the number of heap operations, as well as the number of function calls and case pattern matches. Moreover, the DDE pass could further improve the program's performance by removing additional heap operations.
	
	The compile time statistics demonstrate an interesting phenomena. The number of \pilcode{store}s and function definitions continuously keep decreasing, but at a certain point, the number of \pilcode{fetch}es suddenly increase by a relatively huge margin. This is due to the fact that the optimizer usually performs some preliminary transformations on the GRIN program \emph{before} inlining function definitions. This explains the sudden rise in the number of \pilcode{fetch}es during the early stages of the optimization process. Following that spike, the number of heap operations and function definitions gradually decrease until the program cannot be optimized any further.
	
	\begin{figure}[h]
		\hspace{-0.5cm}
		\renewcommand{\figurename}{Diagram}
		\caption{Length - GRIN statistics}
		\label{diagram:length-stats}
		\addtocounter{figure}{-1}
		\begin{minipage}{0.5\textwidth}
			\subcaption{Runtime}
			\label{diagram:length-stats-rt}
			\includegraphics[scale=0.43]{length-runtime.png}
		\end{minipage}
		\begin{minipage}{0.5\textwidth}
			\subcaption{Compile time}
			\label{diagram:length-stats-ct}
			\includegraphics[scale=0.43]{length-compile-time.png}
		\end{minipage}
	\end{figure}

	The runtime statistics for the executed binary are particularly interesting. First, observing the \pilcode{O0} statistics, we can see that the regular optimizations substantially reduced the number of executed instructions and memory operations, just as we saw with the interpreted GRIN code. Also, it is interesting to see that the DDE optimized binary did not perform any better than the regularly optimized one;  however, its size decreased by more than 20\%. 
	
	We can also notice the huge memory usage difference between the Idris program and the GRIN programs that were only optimized by LLVM but not by GRIN. This because the rather simple code generation scheme of the Idris front end as discussed in \ref{subsec:idris-front-end}. However, after running the optimizations, the optimized GRIN programs consume considerably less memory, and have better execution times as well.
	
	It is worth noting that the Idris binary executed significantly more instructions, and performed a lot more stores and loads than the unoptimized GRIN binary, yet it had a better execution time. The excessive number of memeory operations can be explained by Idris' calling convention. The function arguments are always psuhed onto the stack by the caller, and popped by the callee. This results in a lot of stack memory stores and loads which are reflected in the measurements. However, since the stack memory operations are quite fast, they have no significant impact on the execution times. 
	
	As for the high number of executed instructions, we can only hypothesize that it's caused by the Idris runtime system. Idris uses the runtime system to allocate memory through multiple function calls. In GRIN, the memory operations are kind of "inlined" into the generated LLVM code. This might mean that the binaries generated by the Idris compiler could execute a lot more instructions for every memory operation. 
	
	\begin{center}
		\begin{minipage}{\linewidth}
			\captionof{table}{Length - CPU binary statistics}
			\label{table:length-binary-results}
			\begin{tcolorbox}[tab2,tabularx={l||r|r|r|r|r|r}]
				Stage                 & Size  & Instructions & Stores & Loads & Memory & Time     \\
				\hline\hline
				\pilcode{idris}       &     - & 2822725 & 366880 & 1064977 & 9440 & 0.838 \\\hline
				\pilcode{normal-O0}   & 23928 & 769588  & 212567 & 233305 & 674080 & 1.993 \\\hline
				\pilcode{normal-O3}   & 23928 & 550065  & 160252 & 170202 & 674080 & 1.056 \\\hline
				\pilcode{regular-opt} & 19832 & 257397  & 14848  & 45499  & 8200 & 0.463 \\\hline
				\pilcode{dde-O0}      & 15736 & 256062  & 14243  & 45083  & 5776 & 0.525 \\\hline	
				\pilcode{dde-O3}      & 15736 & 284970  & 33929  & 54555  & 5776 & 0.461 \\
			\end{tcolorbox}	
		\end{minipage}
	\end{center}
	
	Also, it should be pointed out that the aggressively optimized DDE binary performed much worse than the \pilcode{O0} version. This is because the default optimization pipeline of LLVM is designed for the C and C++ languages. As a consequence, in certain scenarios it may perform poorly for other languages. In the future, we plan to construct a better LLVM optimization pipeline for GRIN.

	\subsection{Exact length}
	
	For the GRIN statistics of ``Exact length", we can draw very similar conclusions as for ``Length``. However, closely observing the statistics, we can see, that the DDE pass completely eliminated \emph{all} heap operations from the program. In principle, this means, that all the variables can be put into registers during the execution of the program. In practice, some variables will be spilled onto stack, but the heap will never be used.

	\begin{figure}[h]
		\hspace{-0.5cm}
		\renewcommand{\figurename}{Diagram}
		\caption{Exact length - GRIN statistics}
		\label{diagram:exact-length-stats}
		\addtocounter{figure}{-1}
		\begin{minipage}{0.5\textwidth}
			\subcaption{Runtime}
			\label{diagram:exact-length-stats-rt}
			\includegraphics[scale=0.43]{exact-length-runtime.png}
		\end{minipage}
		\begin{minipage}{0.5\textwidth}
			\subcaption{Compile time}
			\label{diagram:exact-length-stats-ct}
			\includegraphics[scale=0.43]{exact-length-compile-time.png}
		\end{minipage}
	\end{figure}

	The binary statistics show that the optimized GRIN programs really do not use any heap memory. As for the other measured metrics, we do not see any major improvements.

	\begin{center}
		\begin{minipage}{0.96\linewidth}
			\captionof{table}{Exact length - CPU binary statistics}
			\label{table:exact-length-binary-results}
			\begin{tcolorbox}[tab2,tabularx={l||r|r|r|r|r|r}]
				Stage                 & Size  & Instructions & Stores & Loads & Memory & Time      \\
				\hline\hline
				\pilcode{idris}				&     - & 260393 & 23320 & 68334 & 1888 & 0.516 \\\hline
				\pilcode{normal-O0}   & 18800 & 188469 & 14852 & 46566 & 4112 & 0.464 \\\hline
				\pilcode{normal-O3}   & 14704 & 187380 & 14621 & 46233 & 4112 & 0.455 \\\hline
				\pilcode{regular-opt} & 10608 & 183560 & 13462 & 45214 & 112 & 0.451 \\\hline
				\pilcode{dde-O0}      & 10608 & 183413 & 13431 & 45189 & 0 & 0.453 \\\hline
				\pilcode{dde-O3}      & 10608 & 183322 & 13430 & 44226 & 0 & 0.448 \\
			\end{tcolorbox}	
		\end{minipage}
	\end{center}

	\newpage
	\subsection{Type level functions}
	
	The GRIN statistics for this program may not be particularly interesting, but they demonstrate that the GRIN optimizations work for programs with many type level computations as well.
	
	\begin{figure}[h]
		\hspace{-0.5cm}
		\renewcommand{\figurename}{Diagram}
		\caption{Type level functions - GRIN statistics}
		\label{diagram:tyfuns-stats}
		\addtocounter{figure}{-1}
		\begin{minipage}{0.5\textwidth}
			\subcaption{Runtime}
			\label{diagram:tyfuns-stats-rt}
			\includegraphics[scale=0.43]{tyfuns-runtime.png}
		\end{minipage}
		\begin{minipage}{0.5\textwidth}
			\subcaption{Compile time}
			\label{diagram:tyfuns-stats-ct}
			\includegraphics[scale=0.43]{tyfuns-compile-time.png}
		\end{minipage}
	\end{figure}

	The binary statistics look promising for ``Type level functions". Almost all measured performance metrics are strictly decreasing, which suggests that even the default LLVM optimization pipeline can work for GRIN. Also, the optimized GRIN programs use almost half as much memory as the Idris program.

	\begin{center}
		\begin{minipage}{0.97\linewidth}
			\captionof{table}{Type level functions - CPU binary statistics}
			\label{table:tyfuns-binary-results}
			\begin{tcolorbox}[tab2,tabularx={l||r|r|r|r|r|r}]
				Stage                 & Size  & Instructions & Stores & Loads & Memory & Time      \\
				\hline\hline
				\pilcode{idris}       &     - & 525596 & 70841 & 158363 & 29816 & 0.637 \\\hline
				\pilcode{normal-O0}   & 65128 & 383012 & 49191 & 86754  & 44212 & 0.581 \\\hline
				\pilcode{normal-O3}   & 69224 & 377165 & 47556 & 84156  & 44212 & 0.536 \\\hline
				\pilcode{regular-opt} & 36456 & 312122 & 34340 & 71162  & 15412 & 0.516 \\\hline
				\pilcode{dde-O0}      & 32360 & 312075 & 34331 & 70530  & 15236 & 0.532 \\\hline
				\pilcode{dde-O3}      & 28264 & 309822 & 33943 & 70386  & 15236 & 0.513 \\
			\end{tcolorbox}	
		\end{minipage}
	\end{center}

	\subsection{Reverse}
	
	Unlike, the previous programs, ``Reverse" could not have been optimized by the dead data elimination pass. The pass had no effect on it. Fortunately, the regular optimizations alone could considerably improve both the runtime and compile time metrics of the GRIN code.
	
	The binary statistics are rather promising. The binary size decreased by a substantial margin and the number of executed memory operations has also been reduced by quite a lot. Furthermore, the optimized GRIN programs use less than one third of the memory that the Idris program uses.
	
	\begin{figure}[h]
		\hspace{-0.5cm}
		\renewcommand{\figurename}{Diagram}
		\caption{Reverse - GRIN statistics}
		\label{diagram:reverse-stats}
		\addtocounter{figure}{-1}
		\begin{minipage}{0.5\textwidth}
			\subcaption{Runtime}
			\label{diagram:reverse-stats-rt}
			\includegraphics[scale=0.43]{reverse-runtime.png}
		\end{minipage}
		\begin{minipage}{0.5\textwidth}
			\subcaption{Compile time}
			\label{diagram:reverse-stats-ct}
			\includegraphics[scale=0.43]{reverse-compile-time.png}
		\end{minipage}
	\end{figure}
	
	\begin{center}
		\begin{minipage}{\linewidth}
			\captionof{table}{Reverse - CPU binary statistics}
			\label{table:reverse-binary-results}
			\begin{tcolorbox}[tab2,tabularx={l||r|r|r|r|r|r}]
				Stage                 & Size  & Instructions & Stores & Loads & Memory & Speed      \\
				\hline\hline
				\pilcode{idris}          &     - & 350215 & 37893 & 101040 & 7656 & 0.576 \\\hline
				\pilcode{normal-O0}      & 27112 & 240983 & 25018 & 58253  & 18640 & 0.498 \\\hline
				\pilcode{normal-O3}      & 31208 & 236570 & 23808 & 56617  & 18640 & 0.481 \\\hline
				\pilcode{regular-opt-O0} & 14824 & 222085 & 19757 & 53125  & 2384 & 0.467 \\\hline
				\pilcode{regular-opt-O3} & 14824 & 220837 & 19599 & 52827  & 2384 & 0.454 \\
			\end{tcolorbox}	
		\end{minipage}
	\end{center}

	\subsection{General conclusions}
	
	In general, the measurements demonstrate that the GRIN optimizer can considerably improve the performance metrics of a given GRIN program. The regular optimizations themselves can usually produce highly efficient programs, however, in certain cases the dead data elimination pass can facilitate additional optimizations, and can further improve the performance.
	
	The results of the binary measurements indicate that the GRIN optimizer performs optimizations orthogonal to the LLVM optimizations. This supports the motivation behind the framework, which is to transform functional programs into a more manageable format for LLVM by eliminating the functional artifacts. This is backed up by the fact, that none of the fully optimized \pilcode{normal} programs could perform as well as the regularly or DDE optimized ones. Also, it is interesting to see, that there is not much difference between the \pilcode{O0} and \pilcode{O3} default LLVM optimization pipelines for GRIN. This motivates further research to find an optimal pipeline for GRIN. 
	
	Finally, it is rather surprising to see, that the dead data elimination pass did not really impact the performance metrics of the executed binaries, but it significantly reduced their size. Firstly, it might be unorthodox to expect speedup from dead code elimination; however, dead data elimination does not only remove unused code, but it transforms the underlying data representations that the program uses. For instance, it could reduce the size of nodes such that they fit into fewer registers, which could help the register allocator, and thus improve the performance of the program. Also, it could remove the elements of a list, leaving only its spine, thus reducing the initial number of heap operations required to allocate the list. Finally, it could help the garbage collector by not allocating unused heap objects as well as reducing the size of the memory map it has to traverse.
	
	Not seeing any performance gains can be explained by the fact, that most of these programs are quite simple, and do not contain any compound data structures. Dead data elimination can shine when a data structure is used in a specific way, so that it can be locally restructured for each use site. However, when applying it to simple programs, we can obtain sub par results. 
	
	Nevertheless, the binary size reduction is still notable, and demonstrates that even for simple programs, dead data elimination can still have a significant impact.

\end{document}